{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'gulshan e iqbal')]\n",
      "[(2, 'defence')]\n",
      "[(1, 'clifton')]\n",
      "[(1, 'meher plaza')]\n",
      "[(1, 'al murtaza heights')]\n"
     ]
    }
   ],
   "source": [
    "correct_words = ['gulshan e hadeed', 'gulshan e iqbal', 'defence', 'clifton', 'meher plaza', 'al murtaza heights', 'al murtaza height']\n",
    "\n",
    "incorrect_words= ['gulshen iqbal', 'defnse', 'klifton', 'mehar plaza', 'al murteza heights']\n",
    "\n",
    "for word in incorrect_words:\n",
    "\t\ttemp = [(edit_distance(word, w),w) for w in correct_words]\n",
    "\t\t# print(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "\n",
    "\t\tif len(temp) > 1: \n",
    "\t\t\ttemp = [min(temp, key=lambda t: t[0])]\n",
    "\n",
    "\t\tprint(temp)\n",
    "\t\t# print(temp[0][1])\n",
    "\n",
    "# print(edit_distance(incorrect_words[2], correct_words[3]), correct_words[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Neighborhood\n",
      "0         abbas town\n",
      "1     abbasi shaheed\n",
      "2  abdul rehman goth\n",
      "3      abdullah goth\n",
      "4           abidabad\n",
      "File 'karachi_neighbourhoods_lowered.txt' has been created.\n"
     ]
    }
   ],
   "source": [
    "def load_corpus(file_name, pandas=False):\n",
    "    if pandas==True:\n",
    "        df = pd.read_csv(file_name, sep=\"\\t\", header=None, names=[\"Neighborhood\"])\n",
    "        return df\n",
    "    else:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            neighborhood_names = file.readlines()    \n",
    "        refined_name_list = [name.strip() for name in neighborhood_names]\n",
    "        return refined_name_list\n",
    "\n",
    "\n",
    "def lowercase_conversion(text_str):\n",
    "    return text_str.lower()\n",
    "\n",
    "\n",
    "corpus_data = load_corpus(\"karachi_neighbourhoods.txt\")\n",
    "\n",
    "file_name = \"karachi_neighbourhoods_lowered.txt\"\n",
    "\n",
    "with open(file_name, \"w\") as file:\n",
    "    for item in corpus_data:\n",
    "        item = lowercase_conversion(item)\n",
    "        file.write(item + \"\\n\")\n",
    "\n",
    "new_corpus = load_corpus(\"karachi_neighbourhoods_lowered.txt\", True)\n",
    "\n",
    "print(new_corpus.head())\n",
    "\n",
    "print(f\"File '{file_name}' has been created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abbreviations = {\n",
    "    'Apt': 'Apartment',\n",
    "    'Bldg.': 'Building',\n",
    "    'Cantt.': 'Cantonment',\n",
    "    'Col.': 'Colony',\n",
    "    'Ext.': 'Extension',\n",
    "    'Hno.': 'House Number',\n",
    "    'Mkt.': 'Market',\n",
    "    'Ngr.': 'Nagar',\n",
    "    'P.O.': 'Post Office',\n",
    "    'P.O.B': 'Post Office Box',\n",
    "    'Pl.': 'Place',\n",
    "    'Sec.': 'Sector',\n",
    "    'Twn.': 'Town',\n",
    "    'Vlg.': 'Village',\n",
    "    'Dist.': 'District',\n",
    "    'Rd.': 'Road',\n",
    "    'Jct.': 'Junction',\n",
    "    'Ln.': 'Lane',\n",
    "    'Masjid': 'Mosque',\n",
    "    'Fl.': 'Floor',\n",
    "    'Blk.': 'Block',\n",
    "    'Sch.': 'School',\n",
    "    'Univ.': 'University',\n",
    "    'Corp.': 'Corporation',\n",
    "    'Ctr.': 'Center',\n",
    "    'Plz.': 'Plaza',\n",
    "    'Ph.': 'Phase',\n",
    "    'G.P.O.': 'General Post Office',\n",
    "    'Bzr.': 'Bazaar',\n",
    "    'Est.': 'Estate',\n",
    "    'St.': 'Street',\n",
    "    'Ave': 'Avenue',\n",
    "    'Blvd': 'Boulevard',\n",
    "    'Pkwy': 'Parkway',\n",
    "    'Hwy': 'Highway',\n",
    "    'Res.': 'Residential',\n",
    "    'Phase': 'Phase',\n",
    "    'Khy':'Khayaban'\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "punctuation removing: (from sources)\n",
    "- city areas corpus (only has dashes -) -> (solved for capitalization)\n",
    "- abbriviations json -> punctuation + capitalization\n",
    "- data to process -> lowered plus removing all capitalization except for , and - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = 'House # C38, Block 8, Gulshan-e-Iqbal, Karachi'\n",
    "sample2 = 'House No. 123, Street 5, Phase 7, DHA'\n",
    "sample3 = \"House No. 123, St. 5, Phase 7, DHA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def tokenize_address(address):\n",
    "    # Word Tokenization\n",
    "    tokens = address.split()\n",
    "\n",
    "    # Regex Tokenization for capturing specific patterns\n",
    "    # You can customize the regex patterns based on the address format in Pakistan\n",
    "    regex_patterns = [\n",
    "        r'\\d+',  # Capture numerical values (e.g., house numbers)\n",
    "        r'[A-Za-z]+',  # Capture alphabetic words (e.g., street names, city names)\n",
    "        r'\\b[A-Za-z]{2}\\b'  # Capture two-letter abbreviations (e.g., state codes)\n",
    "    ]\n",
    "    tokens_new = []\n",
    "    for pattern in regex_patterns:\n",
    "        regex_tokens = re.findall(pattern, address)\n",
    "        tokens_new.extend(regex_tokens)\n",
    "\n",
    "    return tokens_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', 'Main', 'Street', 'Lahore', 'Punjab']\n",
      "['38', '8', 'House', 'C', 'Block', 'Gulshan', 'e', 'Iqbal', 'Karachi']\n",
      "['123', '5', '7', 'House', 'No', 'Street', 'Phase', 'DHA', 'No']\n",
      "['123', '5', '7', 'House', 'No', 'St', 'Phase', 'DHA', 'No', 'St']\n"
     ]
    }
   ],
   "source": [
    "address = \"12, Main Street, Lahore, Punjab\"\n",
    "# tokens = tokenize_address(address)\n",
    "# print(tokens)\n",
    "\n",
    "print(tokenize_address(address))\n",
    "print(tokenize_address(sample1))\n",
    "print(tokenize_address(sample2))\n",
    "print(tokenize_address(sample3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address 1 Type: House\n",
      "Address 2 Type: Apartment\n",
      "Address 3 Type: Unknown\n"
     ]
    }
   ],
   "source": [
    "def check_address_type(address):\n",
    "    address = address.lower()\n",
    "\n",
    "    house_keywords = ['house no', 'house number', 'house #', 'house']\n",
    "    apartment_keywords = ['flat no', 'flat number', 'flat #', 'flat', 'apartment', 'building']\n",
    "\n",
    "    for keyword in house_keywords:\n",
    "        if keyword in address:\n",
    "            return 'House'\n",
    "\n",
    "    for keyword in apartment_keywords:\n",
    "        if keyword in address:\n",
    "            return 'Apartment'\n",
    "\n",
    "    return 'Unknown'\n",
    "\n",
    "# Example usage:\n",
    "address1 = \"House No. 123, Main Street, New York\"\n",
    "address2 = \"Apartment 7B, Building X, Chicago\"\n",
    "address3 = \"1234 Park Avenue, Los Angeles\"\n",
    "\n",
    "type1 = check_address_type(address1)\n",
    "type2 = check_address_type(address2)\n",
    "type3 = check_address_type(address3)\n",
    "\n",
    "print(f\"Address 1 Type: {type1}\")\n",
    "print(f\"Address 2 Type: {type2}\")\n",
    "print(f\"Address 3 Type: {type3}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Address 1 Type: House\n",
      "Address 2 Type: Apartment\n",
      "Address 3 Type: Unknown\n",
      "Address 4 Type: Apartment\n",
      "Address 5 Type: Both House and Apartment\n"
     ]
    }
   ],
   "source": [
    "def check_address_type(address):\n",
    "    address = address.lower()\n",
    "\n",
    "    house_keywords = ['house no', 'house number', 'house #', 'house']\n",
    "    apartment_keywords = ['flat no', 'flat number', 'flat #', 'flat', 'apartment', 'building']\n",
    "\n",
    "    house_found = any(keyword in address for keyword in house_keywords)\n",
    "    apartment_found = any(keyword in address for keyword in apartment_keywords)\n",
    "\n",
    "    if house_found and apartment_found:\n",
    "        return 'Both House and Apartment'\n",
    "    elif house_found:\n",
    "        return 'House'\n",
    "    elif apartment_found:\n",
    "        return 'Apartment'\n",
    "    else:\n",
    "        return 'Unknown'\n",
    "\n",
    "# Example usage:\n",
    "address1 = \"House No. 123, Main Street, New York\"\n",
    "address2 = \"Apartment 7B, Building X, Chicago\"\n",
    "address3 = \"1234 Park Avenue, Los Angeles\"\n",
    "address4 = \"Flat No. 456, ABC Apartments, London\"\n",
    "address5 = \"House #789, XYZ Building, Sydney\"\n",
    "\n",
    "type1 = check_address_type(address1)\n",
    "type2 = check_address_type(address2)\n",
    "type3 = check_address_type(address3)\n",
    "type4 = check_address_type(address4)\n",
    "type5 = check_address_type(address5)\n",
    "\n",
    "print(f\"Address 1 Type: {type1}\")\n",
    "print(f\"Address 2 Type: {type2}\")\n",
    "print(f\"Address 3 Type: {type3}\")\n",
    "print(f\"Address 4 Type: {type4}\")\n",
    "print(f\"Address 5 Type: {type5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to random_addresses.txt.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "house_keywords = ['house no', 'house number', 'house #', 'house']\n",
    "apartment_keywords = ['flat no', 'flat number', 'flat #', 'flat', 'apartment', 'building']\n",
    "\n",
    "streets = [\"Main Street\", \"Market Road\", \"Gulshan Avenue\", \"Jinnah Boulevard\", \"Civil Lines\", \"Saddar Bazaar\"]\n",
    "localities = [\"Gulberg\", \"Defence\", \"Model Town\", \"Clifton\", \"Nazimabad\", \"PECHS\"]\n",
    "cities = [\"Karachi\", \"Lahore\", \"Islamabad\", \"Rawalpindi\", \"Faisalabad\"]\n",
    "provinces = [\"Sindh\", \"Punjab\", \"Khyber Pakhtunkhwa\", \"Balochistan\", \"Gilgit-Baltistan\", \"Azad Kashmir\"]\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for _ in range(100):\n",
    "    is_house = random.choice([True, False])\n",
    "    \n",
    "    street = random.choice(streets)\n",
    "    locality = random.choice(localities)\n",
    "    city = random.choice(cities)\n",
    "    province = random.choice(provinces)\n",
    "    \n",
    "    if is_house:\n",
    "        house_number = str(random.randint(1, 999))\n",
    "        address_type = random.choice(house_keywords)\n",
    "        address = f\"{address_type} {house_number}, {street}, {locality}, {city}, {province}\"\n",
    "    else:\n",
    "        flat_number = str(random.randint(101, 999))\n",
    "        address_type = random.choice(apartment_keywords)\n",
    "        address = f\"{address_type} {flat_number}, {street}, {locality}, {city}, {province}\"\n",
    "    \n",
    "    dataset.append(address)\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "filename = \"random_addresses.txt\"\n",
    "with open(filename, \"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Address\"])\n",
    "    writer.writerows([address] for address in dataset)\n",
    "\n",
    "print(f\"Dataset saved to {filename}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
