{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "House ORG\n",
      "38 CARDINAL\n",
      "Gulshan GPE\n",
      "Karachi PERSON\n"
     ]
    }
   ],
   "source": [
    "sample1 = 'House # C 38, Block 8 ,Gulshan-e-Iqbal, Karachi'\n",
    "\n",
    "def ner(textstring):\n",
    "    text1= NER(textstring)\n",
    "\n",
    "    for word in text1.ents:\n",
    "        print(word.text,word.label_)\n",
    "\n",
    "ner(sample1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haider Abbas PERSON\n",
      "Al Murtaza School ORG\n",
      "IBA ORG\n",
      "House ORG\n",
      "C-38 PRODUCT\n",
      "Gulshan GPE\n",
      "Karachi PERSON\n"
     ]
    }
   ],
   "source": [
    "sample2 ='Hi, my name is Haider Abbas. I study in class III-B in Al Murtaza School. My university is IBA. I want to be a billionare when I grow up. I live in House  # C-38,  Block  8 , Gulshan-e-Iqbal, Karachi'\n",
    "\n",
    "ner(sample2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple ORG\n",
      "American NORP\n",
      "Cupertino GPE\n",
      "California GPE\n",
      "Steve Jobs PERSON\n",
      "Steve Wozniak PERSON\n",
      "April 1976 DATE\n"
     ]
    }
   ],
   "source": [
    "sample3 = 'Apple is an American tech company whose headquarters are located in Cupertino, California. It was founded by Steve Jobs and Steve Wozniak in April 1976.'\n",
    "\n",
    "ner(sample3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "from nltk.metrics.distance import edit_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 'gulshan e iqbal')]\n",
      "[(2, 'defence')]\n",
      "[(1, 'clifton')]\n",
      "[(1, 'meher plaza')]\n",
      "[(1, 'al murtaza heights')]\n"
     ]
    }
   ],
   "source": [
    "correct_words = ['gulshan e hadeed', 'gulshan e iqbal', 'defence', 'clifton', 'meher plaza', 'al murtaza heights', 'al murtaza height']\n",
    "\n",
    "incorrect_words= ['gulshen iqbal', 'defnse', 'klifton', 'mehar plaza', 'al murteza heights']\n",
    "\n",
    "for word in incorrect_words:\n",
    "\t\ttemp = [(edit_distance(word, w),w) for w in correct_words]\n",
    "\t\t# print(sorted(temp, key = lambda val:val[0])[0][1])\n",
    "\n",
    "\t\tif len(temp) > 1: \n",
    "\t\t\ttemp = [min(temp, key=lambda t: t[0])]\n",
    "\n",
    "\t\tprint(temp)\n",
    "\t\t# print(temp[0][1])\n",
    "\n",
    "# print(edit_distance(incorrect_words[2], correct_words[3]), correct_words[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Neighborhood\n",
      "0         abbas town\n",
      "1     abbasi shaheed\n",
      "2  abdul rehman goth\n",
      "3      abdullah goth\n",
      "4           abidabad\n",
      "File 'karachi_neighbourhoods_lowered.txt' has been created.\n"
     ]
    }
   ],
   "source": [
    "def load_corpus(file_name, pandas=False):\n",
    "    if pandas==True:\n",
    "        df = pd.read_csv(file_name, sep=\"\\t\", header=None, names=[\"Neighborhood\"])\n",
    "        return df\n",
    "    else:\n",
    "        with open(file_name, \"r\") as file:\n",
    "            neighborhood_names = file.readlines()    \n",
    "        refined_name_list = [name.strip() for name in neighborhood_names]\n",
    "        return refined_name_list\n",
    "\n",
    "\n",
    "def lowercase_conversion(text_str):\n",
    "    return text_str.lower()\n",
    "\n",
    "\n",
    "corpus_data = load_corpus(\"karachi_neighbourhoods.txt\")\n",
    "\n",
    "file_name = \"karachi_neighbourhoods_lowered.txt\"\n",
    "\n",
    "with open(file_name, \"w\") as file:\n",
    "    for item in corpus_data:\n",
    "        item = lowercase_conversion(item)\n",
    "        file.write(item + \"\\n\")\n",
    "\n",
    "new_corpus = load_corpus(\"karachi_neighbourhoods_lowered.txt\", True)\n",
    "\n",
    "print(new_corpus.head())\n",
    "\n",
    "print(f\"File '{file_name}' has been created.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "abbreviations_1 = {\n",
    "    \"Apt\": \"Apartment\",\n",
    "    \"Bldg.\": \"Building\",\n",
    "    \"Cantt.\": \"Cantonment\",\n",
    "    \"Col.\": \"Colony\",\n",
    "    \"Ext.\": \"Extension\",\n",
    "    \"Hno.\": \"House Number\",\n",
    "    \"Mkt.\": \"Market\",\n",
    "    \"Ngr.\": \"Nagar\",\n",
    "    \"P.O.\": \"Post Office\",\n",
    "    \"P.O.B\": \"Post Office Box\",\n",
    "    \"Pl.\": \"Place\",\n",
    "    \"Sec.\": \"Sector\",\n",
    "    \"Twn.\": \"Town\",\n",
    "    \"Vlg.\": \"Village\",\n",
    "    \"Dist.\": \"District\",\n",
    "    \"Rd.\": \"Road\",\n",
    "    \"Jct.\": \"Junction\",\n",
    "    \"Ln.\": \"Lane\",\n",
    "    \"Masjid\": \"Mosque\",\n",
    "    \"Fl.\": \"Floor\",\n",
    "    \"Blk.\": \"Block\",\n",
    "    \"Sch.\": \"School\",\n",
    "    \"Univ.\": \"University\",\n",
    "    \"Corp.\": \"Corporation\",\n",
    "    \"Ctr.\": \"Center\",\n",
    "    \"Plz.\": \"Plaza\",\n",
    "    \"Ph.\": \"Phase\",\n",
    "    \"G.P.O.\": \"General Post Office\",\n",
    "    \"Bzr.\": \"Bazaar\",\n",
    "    \"Est.\": \"Estate\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "\n",
    "abbreviations_2 = {\n",
    "    \"St.\": \"Street\",\n",
    "    \"Ave\": \"Avenue\",\n",
    "    \"Rd.\": \"Road\",\n",
    "    \"Blvd\": \"Boulevard\",\n",
    "    \"Plz.\": \"Plaza\",\n",
    "    \"Pkwy\": \"Parkway\",\n",
    "    \"Hwy\": \"Highway\",\n",
    "    \"Sec.\": \"Sector\",\n",
    "    \"Apt\": \"Apartment\",\n",
    "    \"Bldg.\": \"Building\",\n",
    "    \"P.O.\": \"Post Office\",\n",
    "    \"P.O.B\": \"Post Office Box\",\n",
    "    \"G.P.O.\": \"General Post Office\",\n",
    "    \"Jct.\": \"Junction\",\n",
    "    \"Univ.\": \"University\",\n",
    "    \"Est.\": \"Estate\",\n",
    "    \"Cantt.\": \"Cantonment\",\n",
    "    \"Masjid\": \"Mosque\",\n",
    "    \"Res.\": \"Residential\",\n",
    "    \"Col.\": \"Colony\",\n",
    "    \"Ext.\": \"Extension\",\n",
    "    \"Phase\": \"Phase\",\n",
    "    \"Ngr.\": \"Nagar\",\n",
    "    \"Bzr.\": \"Bazaar\",\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "print(len(abbreviations_1))\n",
    "print(len(abbreviations_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys in dict1 from dict2: {'Blk.', 'Vlg.', 'Ctr.', 'Twn.', 'Pl.', 'Ph.', 'Hno.', 'Ln.', 'Sch.', 'Fl.', 'Mkt.', 'Corp.', 'Dist.'}\n",
      "Missing keys in dict2 from dict1: {'Phase', 'Pkwy', 'Blvd', 'Ave', 'Hwy', 'Res.', 'St.'}\n",
      "Missing keys in dict1 from dict2: set()\n",
      "Missing keys in dict2 from dict1: {'Phase', 'Pkwy', 'Blvd', 'Ave', 'Hwy', 'Res.', 'St.'}\n",
      "{'Apt': 'Apartment', 'Bldg.': 'Building', 'Cantt.': 'Cantonment', 'Col.': 'Colony', 'Ext.': 'Extension', 'Hno.': 'House Number', 'Mkt.': 'Market', 'Ngr.': 'Nagar', 'P.O.': 'Post Office', 'P.O.B': 'Post Office Box', 'Pl.': 'Place', 'Sec.': 'Sector', 'Twn.': 'Town', 'Vlg.': 'Village', 'Dist.': 'District', 'Rd.': 'Road', 'Jct.': 'Junction', 'Ln.': 'Lane', 'Masjid': 'Mosque', 'Fl.': 'Floor', 'Blk.': 'Block', 'Sch.': 'School', 'Univ.': 'University', 'Corp.': 'Corporation', 'Ctr.': 'Center', 'Plz.': 'Plaza', 'Ph.': 'Phase', 'G.P.O.': 'General Post Office', 'Bzr.': 'Bazaar', 'Est.': 'Estate'}\n"
     ]
    }
   ],
   "source": [
    "def compare_dictionaries(dict1, dict2):\n",
    "    dict1_keys = set(dict1.keys())\n",
    "    dict2_keys = set(dict2.keys())\n",
    "\n",
    "    dict1_missing_keys = dict1_keys - dict2_keys\n",
    "    dict2_missing_keys = dict2_keys - dict1_keys\n",
    "\n",
    "    return dict1_missing_keys, dict2_missing_keys\n",
    "\n",
    "\n",
    "# Compare the dictionaries\n",
    "missing_keys_dict1, missing_keys_dict2 = compare_dictionaries(abbreviations_1, abbreviations_2)\n",
    "\n",
    "# Print the missing keys\n",
    "print(\"Missing keys in dict1 from dict2:\", missing_keys_dict1)\n",
    "print(\"Missing keys in dict2 from dict1:\", missing_keys_dict2)\n",
    "\n",
    "\n",
    "for x in abbreviations_1:\n",
    "    if x not in abbreviations_2:\n",
    "        abbreviations_2[x] = abbreviations_1[x]\n",
    "\n",
    "missing_keys_dict1, missing_keys_dict2 = compare_dictionaries(abbreviations_1, abbreviations_2)\n",
    "\n",
    "# Print the missing keys\n",
    "print(\"Missing keys in dict1 from dict2:\", missing_keys_dict1)\n",
    "print(\"Missing keys in dict2 from dict1:\", missing_keys_dict2)\n",
    "\n",
    "print(abbreviations_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "print(len(abbreviations_1))\n",
    "print(len(abbreviations_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "{'Apt': 'Apartment', 'Bldg.': 'Building', 'Cantt.': 'Cantonment', 'Col.': 'Colony', 'Ext.': 'Extension', 'Hno.': 'House Number', 'Mkt.': 'Market', 'Ngr.': 'Nagar', 'P.O.': 'Post Office', 'P.O.B': 'Post Office Box', 'Pl.': 'Place', 'Sec.': 'Sector', 'Twn.': 'Town', 'Vlg.': 'Village', 'Dist.': 'District', 'Rd.': 'Road', 'Jct.': 'Junction', 'Ln.': 'Lane', 'Masjid': 'Mosque', 'Fl.': 'Floor', 'Blk.': 'Block', 'Sch.': 'School', 'Univ.': 'University', 'Corp.': 'Corporation', 'Ctr.': 'Center', 'Plz.': 'Plaza', 'Ph.': 'Phase', 'G.P.O.': 'General Post Office', 'Bzr.': 'Bazaar', 'Est.': 'Estate', 'St.': 'Street', 'Ave': 'Avenue', 'Blvd': 'Boulevard', 'Pkwy': 'Parkway', 'Hwy': 'Highway', 'Res.': 'Residential', 'Phase': 'Phase'}\n"
     ]
    }
   ],
   "source": [
    "def combine_dictionaries(dict1, dict2):\n",
    "    combined_dict = dict1.copy()  # Create a copy of the first dictionary\n",
    "    combined_dict.update(dict2)  # Update the copy with the second dictionary\n",
    "\n",
    "    return combined_dict\n",
    "\n",
    "combined_dict = combine_dictionaries(abbreviations_1, abbreviations_2)\n",
    "\n",
    "# Print the combined dictionary\n",
    "\n",
    "print(len(combined_dict))\n",
    "\n",
    "print(combined_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing keys in dict1 from combined_dict: set()\n",
      "Missing keys in combined_dict from dict1: {'Phase', 'Pkwy', 'Blvd', 'Ave', 'Hwy', 'Res.', 'St.'}\n",
      "Missing keys in dict3 from combined_dict: set()\n",
      "Missing keys in combined_dict from dict3: {'Blk.', 'Vlg.', 'Ctr.', 'Twn.', 'Pl.', 'Ph.', 'Hno.', 'Ln.', 'Sch.', 'Fl.', 'Mkt.', 'Corp.', 'Dist.'}\n"
     ]
    }
   ],
   "source": [
    "missing_keys_dict1, missing_keys_dict2 = compare_dictionaries(abbreviations_1, combined_dict)\n",
    "missing_keys_dict3, missing_keys_dict4 = compare_dictionaries(abbreviations_2, combined_dict)\n",
    "\n",
    "# Print the missing keys\n",
    "print(\"Missing keys in dict1 from combined_dict:\", missing_keys_dict1)\n",
    "print(\"Missing keys in combined_dict from dict1:\", missing_keys_dict2)\n",
    "\n",
    "print(\"Missing keys in dict3 from combined_dict:\", missing_keys_dict3)\n",
    "print(\"Missing keys in combined_dict from dict3:\", missing_keys_dict4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Apt': 'Apartment', 'Bldg.': 'Building', 'Cantt.': 'Cantonment', 'Col.': 'Colony', 'Ext.': 'Extension', 'Hno.': 'House Number', 'Mkt.': 'Market', 'Ngr.': 'Nagar', 'P.O.': 'Post Office', 'P.O.B': 'Post Office Box', 'Pl.': 'Place', 'Sec.': 'Sector', 'Twn.': 'Town', 'Vlg.': 'Village', 'Dist.': 'District', 'Rd.': 'Road', 'Jct.': 'Junction', 'Ln.': 'Lane', 'Masjid': 'Mosque', 'Fl.': 'Floor', 'Blk.': 'Block', 'Sch.': 'School', 'Univ.': 'University', 'Corp.': 'Corporation', 'Ctr.': 'Center', 'Plz.': 'Plaza', 'Ph.': 'Phase', 'G.P.O.': 'General Post Office', 'Bzr.': 'Bazaar', 'Est.': 'Estate', 'St.': 'Street', 'Ave': 'Avenue', 'Blvd': 'Boulevard', 'Pkwy': 'Parkway', 'Hwy': 'Highway', 'Res.': 'Residential', 'Phase': 'Phase'}\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(combined_dict)\n",
    "\n",
    "abbreviations = {\n",
    "    'Apt': 'Apartment',\n",
    "    'Bldg.': 'Building',\n",
    "    'Cantt.': 'Cantonment',\n",
    "    'Col.': 'Colony',\n",
    "    'Ext.': 'Extension',\n",
    "    'Hno.': 'House Number',\n",
    "    'Mkt.': 'Market',\n",
    "    'Ngr.': 'Nagar',\n",
    "    'P.O.': 'Post Office',\n",
    "    'P.O.B': 'Post Office Box',\n",
    "    'Pl.': 'Place',\n",
    "    'Sec.': 'Sector',\n",
    "    'Twn.': 'Town',\n",
    "    'Vlg.': 'Village',\n",
    "    'Dist.': 'District',\n",
    "    'Rd.': 'Road',\n",
    "    'Jct.': 'Junction',\n",
    "    'Ln.': 'Lane',\n",
    "    'Masjid': 'Mosque',\n",
    "    'Fl.': 'Floor',\n",
    "    'Blk.': 'Block',\n",
    "    'Sch.': 'School',\n",
    "    'Univ.': 'University',\n",
    "    'Corp.': 'Corporation',\n",
    "    'Ctr.': 'Center',\n",
    "    'Plz.': 'Plaza',\n",
    "    'Ph.': 'Phase',\n",
    "    'G.P.O.': 'General Post Office',\n",
    "    'Bzr.': 'Bazaar',\n",
    "    'Est.': 'Estate',\n",
    "    'St.': 'Street',\n",
    "    'Ave': 'Avenue',\n",
    "    'Blvd':\n",
    "    'Boulevard',\n",
    "    'Pkwy': 'Parkway',\n",
    "    'Hwy': 'Highway',\n",
    "    'Res.': 'Residential',\n",
    "    'Phase': 'Phase'\n",
    "    }\n",
    "\n",
    "if abbreviations == combined_dict:\n",
    "    print(True)\n",
    "else:\n",
    "    print(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "punctuation removing: (from sources)\n",
    "- city areas corpus (only has dashes -)\n",
    "- abbriviations\n",
    "- data to process\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
